# ASR Data Collecter and Preprocessor
A set of Python3.6 scripts to download, preprocess, and analyze xml and wav files of a given language or all languages for ASR training, currently only from http://lacito.vjf.cnrs.fr/pangloss/index_en.html. (Permission has been granted by Pangloss.)

- Running download.py will dump the xml and wav files in the folder "Recordings_xml/" and "Recordings_wav/" respectively, located at the same directory as the script. 
- analyze.py looks at the xml files in "Recordings_xml/" and reports the percentage of IPA/Non-IPA transcriptions and total amount of data in minutes. 
- process.py preprocesses the xml files in "Recordings_xml/" into a .txt in "Processed/", that is easier to read and use by other scripts.
- chars.py looks at the xml files in "Recordings_xml/" and produces character sets (in orthography of language and/or ipa) and additional audio information per language (speaker info in minutes, total data in orthography/ipa)
- undet.py determines the type (orthography vs ipa) of files generated by process.py and chars.py, that couldn't be determined by those scripts.
- generate_all.py will execute process.py, chars.py, undet.py in order.
- persephone_process.py will look at files generated by process.py, and use that information to break down the xml and wav files into utterance chunks that [Persephone](https://github.com/persephone-tools/persephone/tree/master/persephone) can process.
- persephone_process.py requires installation of persephone (pip install persephone), which is not in requirements.txt. However, due to the version of tensorflow used, it's not possible to run this script in a Windows environment, or using Python 3.7.


